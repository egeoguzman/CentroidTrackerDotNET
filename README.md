### Centroid Tracker Algorithm .NET

Aimed to convert very useful python project to .NET project. This project should be useful for object and face detection projects which are developed on .NET platforms.

Inspired from Adrian (Pysearchimage). Thank you for this awesome source.
----------
**Check out the article: [Pyimagesearch - Object Tracking](https://www.pyimagesearch.com/2018/07/23/simple-object-tracking-with-opencv/)**


#### NOTE!: Still available for updates and your contributions :)

**************************
<img width="1048" alt="6" src="https://user-images.githubusercontent.com/32989239/117508665-a8ad9900-af91-11eb-8a3b-5eba9488f7fa.png">
***************************

#### What is Centroid Tracker?

Tracking algorithms are used for tracking surveillance and count them in crowds. Also, these algorithms are implemented to monitoring people and getting real-time count in- formation. In this project, tracking algorithm is used after detection process because according to tests, prediction rate is getting higher when tracking algorithm used. That is because, sys- tem detect a face in frame once, after that gives and ID for each face in frame and tracks them. So that, reasons face detection algorithm does not work for every frame for same faces. This reduce CPU and GPU load and increase the correct prediction rate. It works with simple (x,y) coordinates of caught face and getting centroid of each bounding box and then calculates the euclidean distance between each bounding box of each frame. Assigning ID is working by simple subscribe and unsubscribe method. If one centroid object can not find lowest euclidean value, it means the face that subscribed before is now out of frame, so it unsubscribes it. It is simple euclidean distance matching of centroid points.

#### How it works?

![1](https://user-images.githubusercontent.com/32989239/117505952-887bdb00-af8d-11eb-8c0f-65831e834d2e.png)
>The centroid tracking algorithm presupposes that for each face detected in every single frame we are moving through a set of bounding coordinates (x, y). These bounding boxes can be generated by face detection algorithm, provided they are determined for video streaming.
After getting bounding box coordinates, the center of each box called “centroid” should be calculated and assign unique id for every each centroid.

![2](https://user-images.githubusercontent.com/32989239/117506089-b2350200-af8d-11eb-80aa-444c45327837.png)

>In step 2, compute Euclidean Distance between new bounding boxes and existing objects.

![3](https://user-images.githubusercontent.com/32989239/117506190-de508300-af8d-11eb-9c6a-f83ab952a94e.png)

>If algorithm can not match two points, it register new object to dictionary or deregister an object from dictionary

![4](https://user-images.githubusercontent.com/32989239/117506293-07711380-af8e-11eb-9e8f-e686e80c8daa.png)
![5](https://user-images.githubusercontent.com/32989239/117506321-12c43f00-af8e-11eb-8574-d9a7892d2c9c.png)

*************************************

#### References

* [Centroid Tracker Article](https://irjmets.com/rootaccess/forms/uploads/crowd-counter-an-application-of-centroid-tracking-algorithm.pdf)
* [Pyimagesearch - Object Tracking](https://www.pyimagesearch.com/2018/07/23/simple-object-tracking-with-opencv/)
